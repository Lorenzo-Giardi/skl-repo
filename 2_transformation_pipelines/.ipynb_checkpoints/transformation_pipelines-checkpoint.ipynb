{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation pipelines\n",
    "\n",
    "Several steps:\n",
    "* clean data from missing values\n",
    "* encode categorical features\n",
    "* rescale numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better visualization for long outputs\n",
    "#from IPython.core.display import HTML\n",
    "#display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/lorenzo/skl-repo/0_data/california_housing.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 16512\n",
      "Test set length: 4128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.2, random_state=3542)\n",
    "print(f'Train set length: {len(train)}')\n",
    "print(f'Test set length: {len(test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df original shape: (20640, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'df original shape: {df.shape}')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: remove rows containing null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20433, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: remove columns containing null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('total_bedrooms', axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 3: fill null values with mean, median or other value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median = df['total_bedrooms'].median()\n",
    "df['total_bedrooms'].fillna(median, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice however, that it would be prefereable to compute the median (or mean, or other) only on the training set and then use it to fill the missing values in both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy = 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to momentarily separate numerical features (which can be filled with mean/median) from categorical/string features which can be filled with constant or most frequent values. In this case, we'll simply create a copy of the dataframe without the column 'ocean_proximity'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = train.drop('ocean_proximity', axis=1)\n",
    "test_num = test.drop('ocean_proximity', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit and transform the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_cl = imputer.fit_transform(train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply the same transformation to the test set, without refitting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num_cl = imputer.transform(test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put everything back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = pd.DataFrame(train_num_cl, columns = train_num.columns, index = train_num.index)\n",
    "train_clean['ocean_proximity'] = train['ocean_proximity']\n",
    "test_clean = pd.DataFrame(test_num_cl, columns = test_num.columns, index = test_num.index)\n",
    "test_clean['ocean_proximity'] = test['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 16512\n",
      "Test set length: 4128\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set length: {len(train)}')\n",
    "print(f'Test set length: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "ocean_proximity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is a good idea to separate categorical from numerical features, as their paths temporarily diverge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = train_clean.select_dtypes(exclude=np.number)\n",
    "train_num = train_clean.select_dtypes(include=np.number)\n",
    "test_cat = test_clean.select_dtypes(exclude=np.number)\n",
    "test_num = test_clean.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'median_house_value'],\n",
      "      dtype='object')\n",
      "Categorical columns: Index(['ocean_proximity'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'Numerical columns: {train_num.columns}')\n",
    "print(f'Categorical columns: {train_cat.columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical features\n",
    "Binary features like male/female, can be simply encoded by using one dummy variable. This is equivalent to applying one-hot-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with multi-class categorical features one possible approach is **ordinal encoding**, meaning that a numerical value is attached to each possible original category. However, these numerical labels will have an ordinal dimension, meaning that features whose numerical label is closer, will be interpreted as being more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ocean_proximity\n",
      "4781        <1H OCEAN\n",
      "1512         NEAR BAY\n",
      "14137      NEAR OCEAN\n",
      "2912           INLAND\n",
      "2204           INLAND\n",
      "\n",
      "After encoding: \n",
      "[[0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ord_enc = OrdinalEncoder()\n",
    "train_cat_enc = ord_enc.fit_transform(train_cat)\n",
    "test_cat_enc = ord_enc.transform(test_cat)\n",
    "print(train_cat.head(5))\n",
    "print(f'\\nAfter encoding: \\n{train_cat_enc[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This issue can be fixed by creating a binary attribute (i.e. a dummy variable) for each category (minus one, if the model has a constant). This is called **one-hot-encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ocean_proximity\n",
      "4781        <1H OCEAN\n",
      "1512         NEAR BAY\n",
      "14137      NEAR OCEAN\n",
      "2912           INLAND\n",
      "2204           INLAND\n",
      "\n",
      "After encoding (sparse matrix): \n",
      "  (0, 0)\t1.0\n",
      "  (1, 3)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_enc = OneHotEncoder()\n",
    "train_cat_enc = onehot_enc.fit_transform(train_cat)\n",
    "test_cat_enc = onehot_enc.transform(test_cat)\n",
    "print(train_cat.head(5))\n",
    "print(f'\\nAfter encoding (sparse matrix): \\n{train_cat_enc[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, in order to save memory, this is a SciPy sparse matrix. It can be easily converted to a dense NumPy array by using the toarray() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat_enc.toarray()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformations\n",
    "Custom transformations are especially useful for data cleaning and for combining features. For instance, we may want to computer the number of bedrooms per capita or per household, as it is likely to be much more significant than the overall value.\n",
    "\n",
    "In order to do this, we need to create a new class that implements the fit(), transform() and fit_transform() methods. The latter one can be obtained automatically by subclassing the TransformerMixin class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, beds_ix, pop_ix, hh_ix = 3,4,5,6\n",
    "\n",
    "class CombineAttributes(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, add_bedrooms_per_room = True, X_is_pd_df = False):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        self.X_is_pd_df = X_is_pd_df\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if self.X_is_pd_df: # get and return a pandas DF\n",
    "            X_new = X\n",
    "            X_new['rooms_per_household'] = X['total_rooms'] / X['households']\n",
    "            X_new['avg_household_size'] = X['population'] / X['households']\n",
    "            if self.add_bedrooms_per_room:\n",
    "                X_new['bedrooms_per_room'] = X['total_bedrooms'] / X['total_rooms']\n",
    "            return X_new\n",
    "        \n",
    "        else: # get and return a numpy array\n",
    "            rooms_per_hh = X[:, rooms_ix] / X[:, hh_ix]\n",
    "            avg_hh_size = X[:, pop_ix] / X[:, hh_ix]\n",
    "            if self.add_bedrooms_per_room:\n",
    "                beds_per_room = X[:, beds_ix] / X[:, rooms_ix]\n",
    "                return np.c_[X, rooms_per_hh, avg_hh_size, beds_per_room]\n",
    "            else:\n",
    "                return np.c_[X, rooms_per_hh, avg_hh_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>avg_household_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>-118.32</td>\n",
       "      <td>34.04</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>2.8654</td>\n",
       "      <td>176800.0</td>\n",
       "      <td>4.520179</td>\n",
       "      <td>2.439462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>-122.03</td>\n",
       "      <td>37.91</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5438.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>5.0362</td>\n",
       "      <td>275300.0</td>\n",
       "      <td>6.110112</td>\n",
       "      <td>2.595506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14137</th>\n",
       "      <td>-117.05</td>\n",
       "      <td>32.74</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>3.1719</td>\n",
       "      <td>115300.0</td>\n",
       "      <td>4.883408</td>\n",
       "      <td>2.674888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>-119.05</td>\n",
       "      <td>35.36</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4507.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>959.0</td>\n",
       "      <td>3.3261</td>\n",
       "      <td>118400.0</td>\n",
       "      <td>4.699687</td>\n",
       "      <td>2.357664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>-119.85</td>\n",
       "      <td>36.82</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>5.5842</td>\n",
       "      <td>88900.0</td>\n",
       "      <td>7.112821</td>\n",
       "      <td>3.271795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "4781     -118.32     34.04                44.0       1008.0           223.0   \n",
       "1512     -122.03     37.91                29.0       5438.0           871.0   \n",
       "14137    -117.05     32.74                34.0       2178.0           455.0   \n",
       "2912     -119.05     35.36                16.0       4507.0          1049.0   \n",
       "2204     -119.85     36.82                15.0       1387.0           236.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "4781        544.0       223.0         2.8654            176800.0   \n",
       "1512       2310.0       890.0         5.0362            275300.0   \n",
       "14137      1193.0       446.0         3.1719            115300.0   \n",
       "2912       2261.0       959.0         3.3261            118400.0   \n",
       "2204        638.0       195.0         5.5842             88900.0   \n",
       "\n",
       "       rooms_per_household  avg_household_size  \n",
       "4781              4.520179            2.439462  \n",
       "1512              6.110112            2.595506  \n",
       "14137             4.883408            2.674888  \n",
       "2912              4.699687            2.357664  \n",
       "2204              7.112821            3.271795  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_attr = CombineAttributes(add_bedrooms_per_room=False, X_is_pd_df=True)\n",
    "train_num_cstm = comb_attr.transform(train_num)\n",
    "test_num_cstm = comb_attr.transform(test_num)\n",
    "train_num_cstm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling numerical features\n",
    "**Min-max scaling** (often called normalization) shifts and rescales values so that they they up ranging from 0 to 1 (or another provided range). This guarantess maximum stability, however, it is negatively affected by the presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01894059, 0.08076883, 0.04166229, ..., 0.06525925, 0.04043693,\n",
       "       0.02590764])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "norm_scl = MinMaxScaler()\n",
    "train_num_norm = norm_scl.fit_transform(train_num_cstm)\n",
    "test_num_norm = norm_scl.transform(test_num_cstm)\n",
    "train_num_norm[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardization** shifts and rescales the data by subtracting its mean and dividing by its standard deviation, so that the resulting distribution has zero mean and unitary variance. Because standardized values are potentially unbounded, it is less afftected by outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.79577658,  0.80422823, -0.20777934, ...,  0.40286802,\n",
       "       -0.23948951, -0.61548158])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scl = StandardScaler()\n",
    "train_num_std = std_scl.fit_transform(train_num_cstm)\n",
    "test_num_std = std_scl.transform(test_num_cstm)\n",
    "train_num_std[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Pipelines\n",
    "All these preceeding steps can be grouped together using a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pipeline for numerical columns\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('cstm_attribs', CombineAttributes()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "train_num_trs = num_pipeline.fit_transform(train_num)\n",
    "test_num_trs = num_pipeline.transform(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for categorical columns\n",
    "cat_pipeline = Pipeline([\n",
    "    ('onehot_enc', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "train_cat_trs = cat_pipeline.fit_transform(train_cat)\n",
    "test_cat_trs = cat_pipeline.transform(test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "train_cat = train_clean.select_dtypes(exclude=np.number)\n",
    "train_num = train_clean.select_dtypes(include=np.number)\n",
    "test_cat = test_clean.select_dtypes(exclude=np.number)\n",
    "test_num = test_clean.select_dtypes(include=np.number)\n",
    "\n",
    "num_columns = list(train_num.columns)\n",
    "cat_columns = list(train_cat.columns)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_columns),\n",
    "    ('cat', cat_pipeline, cat_columns),\n",
    "])\n",
    "\n",
    "train_prepared = full_pipeline.fit_transform(train_clean)\n",
    "test_prepared = full_pipeline.transform(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62065428, -0.74474072,  1.22386067, -0.75003355, -0.75231554,\n",
       "        -0.79577658, -0.72493135, -0.52648186, -0.25321123, -0.35676013,\n",
       "        -0.09283641,  0.11433985,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.23173899,  1.06568   ,  0.03068215,  1.29781199,  0.80576131,\n",
       "         0.80422823,  1.0319955 ,  0.62398626,  0.60317048,  0.26105877,\n",
       "        -0.06757662, -0.81767437,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.25476194, -1.35289239,  0.42840832, -0.20918044, -0.19448555,\n",
       "        -0.20777934, -0.13753302, -0.36404475, -0.78790641, -0.21561609,\n",
       "        -0.05472651, -0.07375281,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.25616719, -0.12723288, -1.00340591,  0.86744084,  1.23375156,\n",
       "         0.75983399,  1.21374655, -0.28232272, -0.7609543 , -0.28700668,\n",
       "        -0.10607752,  0.29016044,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.14327071,  0.55576822, -1.08295115, -0.57483412, -0.72105782,\n",
       "        -0.71061211, -0.7986854 ,  0.91441216, -1.0174341 ,  0.65069283,\n",
       "         0.04189862, -0.66530903,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prepared[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy36",
   "language": "python",
   "name": "newpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
