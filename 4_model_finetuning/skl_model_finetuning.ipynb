{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/lorenzo/skl-repo/0_data/california_housing.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "X = df.drop('median_house_value', axis=1)\n",
    "y = df['median_house_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 16512\n",
      "Test set length: 4128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state=3542)\n",
    "print(f'Train set length: {len(train_X)}')\n",
    "print(f'Test set length: {len(test_X)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, beds_ix, pop_ix, hh_ix = 3,4,5,6\n",
    "\n",
    "class CombineAttributes(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_hh = X[:, rooms_ix] / X[:, hh_ix]\n",
    "        avg_hh_size = X[:, pop_ix] / X[:, hh_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            beds_per_room = X[:, beds_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_hh, avg_hh_size, beds_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_hh, avg_hh_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_cat = train_X.select_dtypes(exclude=np.number)\n",
    "trainX_num = train_X.select_dtypes(include=np.number)\n",
    "testX_cat = test_X.select_dtypes(exclude=np.number)\n",
    "testX_num = test_X.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_columns = list(trainX_num.columns)\n",
    "cat_columns = list(trainX_cat.columns)\n",
    "\n",
    "# pipeline for numerical columns\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = 'median')),\n",
    "    ('cstm_attribs', CombineAttributes()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# pipeline for categorical columns\n",
    "cat_pipeline = Pipeline([\n",
    "    ('onehot_enc', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "# full pipeline\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_columns),\n",
    "    ('cat', cat_pipeline, cat_columns),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pipeline transformation to features (X)\n",
    "train_X = full_pipeline.fit_transform(train_X)\n",
    "test_X = full_pipeline.transform(test_X)\n",
    "\n",
    "# Convert target to numpy array (y)\n",
    "train_y, test_y = train_y.values, test_y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model (untuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline random forest RMSE: 50845.35324493719\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1)\n",
    "rf.fit(train_X, train_y)\n",
    "\n",
    "rf_pred = rf.predict(test_X)\n",
    "rf_mse = mean_squared_error(test_y, rf_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "print(f'Baseline random forest RMSE: {rf_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid=[{'max_depth': [None, 5, 10],\n",
       "                          'min_samples_leaf': [1, 3, 5],\n",
       "                          'n_estimators': [10, 50]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters_grid = [\n",
    "    {'n_estimators': [10, 50], 'min_samples_leaf':[1, 3, 5], 'max_depth':[None, 5, 10]},\n",
    "    # alternative combinations can be added with more dictionaries\n",
    "    # {}\n",
    "]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(rf, parameters_grid, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 50}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52468.70323642938 {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 10}\n",
      "50365.4226809366 {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "51991.026592453534 {'max_depth': None, 'min_samples_leaf': 3, 'n_estimators': 10}\n",
      "50372.311833637665 {'max_depth': None, 'min_samples_leaf': 3, 'n_estimators': 50}\n",
      "52345.9189791181 {'max_depth': None, 'min_samples_leaf': 5, 'n_estimators': 10}\n",
      "50831.28973792548 {'max_depth': None, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "64358.18050700863 {'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 10}\n",
      "63778.28788496295 {'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "63837.118788949425 {'max_depth': 5, 'min_samples_leaf': 3, 'n_estimators': 10}\n",
      "63714.60116814434 {'max_depth': 5, 'min_samples_leaf': 3, 'n_estimators': 50}\n",
      "63937.15285023483 {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 10}\n",
      "63761.69979003445 {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 50}\n",
      "54008.88904458058 {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 10}\n",
      "53006.258972127835 {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 50}\n",
      "53921.37177693209 {'max_depth': 10, 'min_samples_leaf': 3, 'n_estimators': 10}\n",
      "52809.43468529075 {'max_depth': 10, 'min_samples_leaf': 3, 'n_estimators': 50}\n",
      "53920.151454030056 {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 10}\n",
      "52998.76170631266 {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned random forest RMSE: 50830.86914545845\n"
     ]
    }
   ],
   "source": [
    "tuned_rf = grid_search.best_estimator_\n",
    "\n",
    "rf_pred = tuned_rf.predict(test_X)\n",
    "rf_mse = mean_squared_error(test_y, rf_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "print(f'Tuned random forest RMSE: {rf_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                   iid='deprecated', n_iter=20, n_jobs=-1,\n",
       "                   param_distributions=[{'max_depth': [None, 10],\n",
       "                                         'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f59bc320950>,\n",
       "                                         'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f59b9772b90>}],\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_squared_error',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, norm, randint\n",
    "\n",
    "distributions = [\n",
    "    {'n_estimators': randint(10, 100), 'min_samples_leaf': randint(1, 10), 'max_depth': [None, 10]},\n",
    "    # alternative combinations can be added with more dictionaries\n",
    "    # {}\n",
    "]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rndm_seach = RandomizedSearchCV(rf, distributions, n_iter = 20, cv=5, scoring=\"neg_mean_squared_error\", \n",
    "                           return_train_score=True, n_jobs=-1, )\n",
    "\n",
    "rndm_seach.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 90}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndm_seach.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51107.97019675681 {'max_depth': None, 'min_samples_leaf': 7, 'n_estimators': 57}\n",
      "50601.581484899376 {'max_depth': None, 'min_samples_leaf': 5, 'n_estimators': 95}\n",
      "51042.50763934293 {'max_depth': None, 'min_samples_leaf': 6, 'n_estimators': 58}\n",
      "51172.69593087151 {'max_depth': None, 'min_samples_leaf': 7, 'n_estimators': 56}\n",
      "52881.71751248242 {'max_depth': 10, 'min_samples_leaf': 7, 'n_estimators': 80}\n",
      "53067.4811102635 {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 49}\n",
      "51460.74174465332 {'max_depth': None, 'min_samples_leaf': 6, 'n_estimators': 20}\n",
      "51007.42778904997 {'max_depth': None, 'min_samples_leaf': 7, 'n_estimators': 99}\n",
      "51277.48777974723 {'max_depth': None, 'min_samples_leaf': 8, 'n_estimators': 82}\n",
      "51659.3707531114 {'max_depth': None, 'min_samples_leaf': 9, 'n_estimators': 42}\n",
      "51627.60504936137 {'max_depth': None, 'min_samples_leaf': 9, 'n_estimators': 67}\n",
      "50081.92806421921 {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 90}\n",
      "52948.202116099295 {'max_depth': 10, 'min_samples_leaf': 7, 'n_estimators': 78}\n",
      "52932.31344844043 {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 83}\n",
      "52771.5385345649 {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 86}\n",
      "51270.408143822664 {'max_depth': None, 'min_samples_leaf': 7, 'n_estimators': 51}\n",
      "50242.81875622805 {'max_depth': None, 'min_samples_leaf': 3, 'n_estimators': 90}\n",
      "50389.91945901697 {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 44}\n",
      "52885.73438917286 {'max_depth': 10, 'min_samples_leaf': 6, 'n_estimators': 56}\n",
      "51480.05987141205 {'max_depth': None, 'min_samples_leaf': 9, 'n_estimators': 84}\n"
     ]
    }
   ],
   "source": [
    "cvres = rndm_seach.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned random forest RMSE: 50706.591774714696\n"
     ]
    }
   ],
   "source": [
    "tuned_rf = rndm_seach.best_estimator_\n",
    "\n",
    "rf_pred = tuned_rf.predict(test_X)\n",
    "rf_mse = mean_squared_error(test_y, rf_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "print(f'Tuned random forest RMSE: {rf_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpy36",
   "language": "python",
   "name": "newpy36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
